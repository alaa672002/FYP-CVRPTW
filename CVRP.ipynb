{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+4fZUh+dlQ44S3Sr/54bk"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install googlemaps\n",
        "\n",
        "!pip install ortools\n",
        "\n",
        "!pip install gmaps"
      ],
      "metadata": {
        "id": "maZCXO43-SGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions and imports"
      ],
      "metadata": {
        "id": "yi_jHTMUj1cS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import folium\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import haversine_distances\n",
        "from math import radians\n",
        "import matplotlib.cm as cm\n",
        "import warnings\n",
        "from folium import plugins\n",
        "import matplotlib.colors as colors\n",
        "\n",
        "import googlemaps\n",
        "from itertools import tee,islice\n",
        "import time\n",
        "import ast\n",
        "import json\n",
        "from ortools.constraint_solver import routing_enums_pb2\n",
        "from ortools.constraint_solver import pywrapcp\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import collections\n",
        "collections.Iterable = collections.abc.Iterable\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "import gmaps\n",
        "import gmaps.datasets\n",
        "\n",
        "def combine_lat_lon(df):\n",
        "    \"\"\"This function combines latitude and longitude columns from a dataframe\n",
        "     into a single column named 'coordinates'.\"\"\"\n",
        "    df['coordinates'] = list(zip(df['latitude'], df['longitude']))\n",
        "    return df\n",
        "\n",
        "def run_kmeans(orders_df, vehicle_df,num_clusters):\n",
        "    \"\"\"This function performs KMeans clustering on the coordinates of orders.\n",
        "     It assigns each order to a cluster and returns the updated orders dataframe along with the KMeans model.\"\"\"\n",
        "    kmeans = KMeans(n_clusters=num_clusters, n_init=30)\n",
        "    kmeans.fit(list(orders_df['coordinates']))\n",
        "    orders_df['cluster'] = kmeans.labels_\n",
        "    return orders_df, kmeans\n",
        "\n",
        "def print_clusters(orders_df, kmeans):\n",
        "    \"\"\"This function prints the orders in each cluster identified by KMeans clustering.\"\"\"\n",
        "    cluster_ids = np.unique(kmeans.labels_)\n",
        "    for cluster_id in range(len(cluster_ids)):\n",
        "        cluster_orders = orders_df[orders_df['cluster'] == cluster_id]['order_id']\n",
        "        print(f\"Cluster {cluster_id}: Orders {', '.join(cluster_orders.astype(str))}\")\n",
        "\n",
        "def plot_clusters(orders_df,depot_coordinates, filename='cluster_map.html'):\n",
        "    \"\"\"This function plots the clusters on a map using Folium library\n",
        "    and saves it to an HTML file. It also marks a depot location on the map.\"\"\"\n",
        "    map_center = [np.mean(orders_df['latitude']), np.mean(orders_df['longitude'])]\n",
        "    m = folium.Map(location=map_center, zoom_start=10, width=1200, height=800)\n",
        "    colors = ['red', 'green', 'blue', 'yellow', 'cyan', 'magenta', 'black', 'orange']\n",
        "    clusters = orders_df['cluster'].unique()\n",
        "    cmap = cm.get_cmap('magma', len(clusters))\n",
        "\n",
        "    for idx, row in orders_df.iterrows():\n",
        "        color = cmap(clusters.tolist().index(row['cluster']))\n",
        "        color_hex = \"#{:02x}{:02x}{:02x}\".format(int(color[0] * 255), int(color[1] * 255), int(color[2] * 255))\n",
        "\n",
        "        folium.CircleMarker(location=row['coordinates'], color=color_hex, fill=True, fill_opacity=1, radius=10, tooltip=f\"Order ID: {row['order_id']}\").add_to(m)\n",
        "        # rm if dont want order id\n",
        "        folium.Marker(location=row['coordinates'], popup=f\"Order ID: {row['order_id']}\", icon=None).add_to(m)\n",
        "\n",
        "        folium.Marker(location=row['coordinates'], icon=folium.DivIcon(html=f\"<div style='font-size: 12pt; color: black; position: fixed; right: +10px;'>{row['cluster']}</div>\")).add_to(m)\n",
        "\n",
        "    folium.Marker(location=depot_coordinates, icon=folium.Icon(color='red'), tooltip=\"Depot\").add_to(m)\n",
        "    m.save(filename)\n",
        "    return m\n",
        "\n",
        "def haversine(point1, point2):\n",
        "    \"\"\"Calculate haversine distance between two points given their latitude and longitude coordinates.\"\"\"\n",
        "    point1 = [radians(coord) for coord in point1]\n",
        "    point2 = [radians(coord) for coord in point2]\n",
        "    distance = haversine_distances([point1, point2])\n",
        "    return distance[0][1] * 6371000/ 1609.34 # multiply by Earth radius to get meters\n",
        "\n",
        "def select_nearest_cluster(orders_df, leaving_point):\n",
        "    \"\"\"This function selects the nearest cluster to a given leaving point (typically the current location of a vehicle).\"\"\"\n",
        "    orders_df['distance_to_leaving_point'] = orders_df['coordinates'].apply(lambda x: haversine(x, leaving_point))\n",
        "    nearest_cluster = orders_df.loc[orders_df['distance_to_leaving_point'].idxmin()]\n",
        "    id = nearest_cluster['cluster']\n",
        "    print(f'\\n\\n going to nearest cluster {id}')\n",
        "    return nearest_cluster\n",
        "\n",
        "def get_nearest_cluster_orders(orders_df,current_point):\n",
        "    \"\"\" This function retrieves orders from the nearest cluster to a given current point.\"\"\"\n",
        "    nearest_cluster = select_nearest_cluster(orders_df, current_point)\n",
        "    print(f\"trying to get orders from nearest cluster \\n {nearest_cluster['cluster']}\")\n",
        "    nearest_cluster_orders = orders_df[orders_df['cluster'] == nearest_cluster['cluster']]\n",
        "    nearest_cluster_orders = nearest_cluster_orders.sort_values(by='distance_to_leaving_point')\n",
        "    return nearest_cluster, nearest_cluster_orders\n",
        "\n",
        "def assign_vehicle(nearest_cluster, vehicle_df):\n",
        "    \"\"\"This function assigns the first vehicle from the vehicle dataframe to the nearest cluster.\"\"\"\n",
        "    vehicle_id = vehicle_df.iloc[0]['vehicle_id']\n",
        "    vehicle_capacity = vehicle_df.iloc[0]['vehicle_capacity ']\n",
        "    return vehicle_id, vehicle_capacity\n",
        "\n",
        "def nearest_cluster_collection(nearest_cluster_orders,exceeds_weight_orders,remaining_capacity,collected_orders,current_point):\n",
        "    \"\"\" This function collects orders from the nearest cluster to a given current point, considering vehicle capacity constraints.\"\"\"\n",
        "    while len(nearest_cluster_orders) >=1:\n",
        "      # current_point = (order['latitude'],order['longitude'])\n",
        "      nearest_cluster_orders['distance_to_leaving_point'] = nearest_cluster_orders['coordinates'].apply(lambda x: haversine(x, current_point))\n",
        "      nearest_cluster_orders = nearest_cluster_orders.sort_values(by='distance_to_leaving_point')\n",
        "      order = nearest_cluster_orders.iloc[0]\n",
        "      #display(order)\n",
        "      nearest_cluster_orders= nearest_cluster_orders.drop(nearest_cluster_orders.index[0])\n",
        "\n",
        "      if order['order_weight'] <= remaining_capacity:\n",
        "          # print(f'net_weight: {net_weight}')\n",
        "          current_order = order['order_id']\n",
        "          current_weight = order['order_weight']\n",
        "          collected_orders.append(current_order)\n",
        "          remaining_capacity -= current_weight\n",
        "\n",
        "          print(f'collected order {current_order} with weight {current_weight} .remaining capacity: {remaining_capacity}')\n",
        "          current_point = (order['latitude'],order['longitude'])\n",
        "      # if the order is > than the capacity\n",
        "      # try to get the following orders of the cluster\n",
        "      else:\n",
        "          exceeds_weight_order = order['order_weight']\n",
        "          exceeds_weight_order_id = order['order_id']\n",
        "          # print(f'cant take {exceeds_weight_order} from order {exceeds_weight_order_id}')\n",
        "          exceeds_weight_orders.append(exceeds_weight_order_id)\n",
        "\n",
        "    return collected_orders,exceeds_weight_orders,remaining_capacity,current_point\n",
        "\n",
        "def print_uncollected_orders(exceeds_weight_orders):\n",
        "    \"\"\"This function prints the uncollected orders (orders that couldn't be collected due to weight constraints).\"\"\"\n",
        "    if len(exceeds_weight_orders) >= 1:\n",
        "      print(f'could not collects orders: {exceeds_weight_orders}')\n",
        "      exceeds_weight_orders = []\n",
        "    else:\n",
        "      print('collected all orders of cluster')\n",
        "    return exceeds_weight_orders\n",
        "\n",
        "def remove_collected_cluster(nearest_cluster,unique_clusters,valid_orders_df):\n",
        "    \"\"\" This function removes the collected cluster from the list of unique clusters and updates the valid orders dataframe.\"\"\"\n",
        "    ncid = nearest_cluster['cluster']\n",
        "    print(f'removing cluster {ncid} from {unique_clusters}')\n",
        "    unique_clusters = np.delete(unique_clusters, unique_clusters==nearest_cluster['cluster'])\n",
        "    valid_orders_df = valid_orders_df[valid_orders_df['cluster'] != ncid]\n",
        "\n",
        "    print(f\"{len(valid_orders_df)} orders still are valid and can be taken\")\n",
        "    return ncid,unique_clusters,valid_orders_df\n",
        "\n",
        "\n",
        "def collect_orders(nearest_cluster,nearest_cluster_orders, vehicle_capacity,orders_df,current_point,mode='nearest_cluster',distance_threshold = 5):\n",
        "    \"\"\"This function collects orders until the vehicle capacity is reached, either from the nearest cluster or from clusters within a specified distance threshold.\"\"\"\n",
        "    collected_orders = []\n",
        "    exceeds_weight_orders = []\n",
        "    remaining_capacity = vehicle_capacity\n",
        "\n",
        "    orders_df = remove_collected_orders(orders_df, collected_orders)\n",
        "\n",
        "    collected_orders,exceeds_weight_orders,remaining_capacity,current_point = nearest_cluster_collection(nearest_cluster_orders,\n",
        "                                                                                                         exceeds_weight_orders,\n",
        "                                                                                                         remaining_capacity,\n",
        "                                                                                                         collected_orders,current_point)\n",
        "    # print all uncollected orders at once and restart list\n",
        "    exceeds_weight_orders = print_uncollected_orders(exceeds_weight_orders)\n",
        "\n",
        "    # update orders df\n",
        "    orders_df = remove_collected_orders(orders_df, collected_orders)\n",
        "\n",
        "    # 2. Mode nearest cluster try to get the order only of nearest cluster\n",
        "    if mode == 'nearest_cluster':\n",
        "      # order by distance point again\n",
        "      try:\n",
        "        # reorder it as now its a different point - last point visited on first cluster\n",
        "        orders_df['distance_to_leaving_point'] = orders_df['coordinates'].apply(lambda x: haversine(x, current_point))\n",
        "        orders_df = orders_df.sort_values(by='distance_to_leaving_point')\n",
        "\n",
        "        valid_orders_df = orders_df\n",
        "\n",
        "        unique_clusters = orders_df['cluster'].unique()\n",
        "\n",
        "        ncid,unique_clusters,valid_orders_df = remove_collected_cluster(nearest_cluster,unique_clusters,valid_orders_df)\n",
        "\n",
        "        print(unique_clusters, 'unique clusters left.')\n",
        "\n",
        "        nearest_cluster, nearest_cluster_orders = get_nearest_cluster_orders(valid_orders_df,current_point)\n",
        "\n",
        "        collected_orders,exceeds_weight_orders,remaining_capacity,current_point = nearest_cluster_collection(nearest_cluster_orders,\n",
        "                                                                                                             exceeds_weight_orders,\n",
        "                                                                                                             remaining_capacity,\n",
        "                                                                                                             collected_orders,current_point)\n",
        "        exceeds_weight_orders = print_uncollected_orders(exceeds_weight_orders)\n",
        "\n",
        "      except TypeError as e:\n",
        "        print(f\"no other cluster available: {e}\")\n",
        "\n",
        "      orders_df = remove_collected_orders(orders_df, collected_orders)\n",
        "      print(f'remaining_capacity: {remaining_capacity}')\n",
        "\n",
        "    # 3. try to get orders from the following nearest clusters\n",
        "    if mode == 'distance_threshold':\n",
        "\n",
        "      # filter orders valid in terms of distance threshold\n",
        "      # reorder it as now its a different point - last point visited on first cluster\n",
        "      orders_df['distance_to_leaving_point'] = orders_df['coordinates'].apply(lambda x: haversine(x, current_point))\n",
        "\n",
        "      valid_orders_df = orders_df[orders_df['distance_to_leaving_point'] <= distance_threshold]\n",
        "      high_threshold_orders = orders_df[orders_df['distance_to_leaving_point'] > distance_threshold]\n",
        "      exceeds_weight_orders = print_uncollected_orders(exceeds_weight_orders)\n",
        "      unique_clusters = valid_orders_df['cluster'].unique()\n",
        "\n",
        "      ncid,unique_clusters,valid_orders_df = remove_collected_cluster(nearest_cluster,unique_clusters,valid_orders_df)\n",
        "\n",
        "      print(unique_clusters, 'unique clusters with orders matching distance threshold.')\n",
        "\n",
        "      while len(unique_clusters) >= 1:\n",
        "        try:\n",
        "\n",
        "          nearest_cluster, nearest_cluster_orders = get_nearest_cluster_orders(valid_orders_df,current_point)\n",
        "\n",
        "          collected_orders,exceeds_weight_orders,remaining_capacity,current_point = nearest_cluster_collection(nearest_cluster_orders,\n",
        "                                                                                                               exceeds_weight_orders,\n",
        "                                                                                                               remaining_capacity,\n",
        "                                                                                                               collected_orders,current_point)\n",
        "          # print all uncollected orders at once and restart list\n",
        "          exceeds_weight_orders = print_uncollected_orders(exceeds_weight_orders)\n",
        "\n",
        "          ncid,unique_clusters,valid_orders_df = remove_collected_cluster(nearest_cluster,unique_clusters,valid_orders_df)\n",
        "\n",
        "        except TypeError:\n",
        "            print(\"No other cluster available meeting distance threshold.\")\n",
        "            orders_df = remove_collected_orders(orders_df, collected_orders)\n",
        "            break\n",
        "\n",
        "      orders_df = remove_collected_orders(orders_df, collected_orders)\n",
        "      print(f'remaining_capacity: {remaining_capacity}')\n",
        "    return collected_orders,remaining_capacity\n",
        "\n",
        "def remove_collected_orders(orders_df, collected_orders):\n",
        "    \"\"\"Remove collected orders from the data.\"\"\"\n",
        "    orders_df = orders_df[~orders_df['order_id'].isin(collected_orders)]\n",
        "    return orders_df\n",
        "\n",
        "def remove_vehicle(vehicle_df, vehicle_id):\n",
        "    \"\"\"Remove vehicle orders from the data.\"\"\"\n",
        "    vehicle_df = vehicle_df[vehicle_df['vehicle_id']!=vehicle_id]\n",
        "    return vehicle_df\n",
        "\n",
        "def plot_routes_with_points(df_results, orders_df, depot_coordinates, filename='routes_map_with_points.html'):\n",
        "    \"\"\"Plot routes and points for each truck on a folium map and save it to an HTML file.\"\"\"\n",
        "     #Create a map centered around the depot\n",
        "    m = folium.Map(location=depot_coordinates, zoom_start=10)#,tiles='Stamen Terrain'\n",
        "\n",
        "    # Define colors for each route\n",
        "    num_trucks = len(df_results)\n",
        "    colormap = cm.get_cmap('tab20b', num_trucks)\n",
        "    # Plot points for each order\n",
        "    for idx, row in orders_df.iterrows():\n",
        "        folium.CircleMarker(location=(row['latitude'], row['longitude']), radius=5, color='black', fill=True, fill_color='black').add_to(m)\n",
        "\n",
        "    legend_html = '<div style=\"position: fixed; top: 50px; left: 50px; z-index:9999; font-size: 14px; background-color:white; border-radius: 5px; padding: 10px;\">'\n",
        "    # Plot each route\n",
        "    for idx, row in df_results.iterrows():\n",
        "        vehicle_id = row['vehicle_id']\n",
        "        orders = row['orders']\n",
        "        route_coordinates = [depot_coordinates]  # Start with depot\n",
        "        print(vehicle_id,orders,route_coordinates)\n",
        "        for order_id in orders:\n",
        "            order = orders_df.loc[orders_df['order_id'] == order_id]\n",
        "            # print(order)\n",
        "            order_coordinates = (order['latitude'].values[0], order['longitude'].values[0])\n",
        "            route_coordinates.append(order_coordinates)\n",
        "        route_coordinates.append(depot_coordinates)  # End at depot\n",
        "\n",
        "        # Plot route on map with color for each truck\n",
        "        color = colors.rgb2hex(colormap(idx)[:3])\n",
        "        folium.PolyLine(locations=route_coordinates, color=color, weight=2.5, opacity=1).add_to(m)\n",
        "        legend_html += f'<div style=\"margin-bottom: 5px;\"><i class=\"fa fa-square\" style=\"color:{color}\"></i> Vehicle {vehicle_id}</div>'\n",
        "    legend_html += '</div>'\n",
        "\n",
        "    m.get_root().html.add_child(folium.Element(legend_html))\n",
        "    # Save map to HTML file\n",
        "    # m.save(filename)\n",
        "    return m\n",
        "\n",
        "def perform_clustering(orders_df, vehicle_df,mode):\n",
        "\n",
        "    #This function performs clustering on orders and adjusts the number of clusters based on the mode provided.\n",
        "    if mode == 'distance_threshold':\n",
        "        try:\n",
        "            orders_df, kmeans = run_kmeans(orders_df, vehicle_df, num_clusters=len(vehicle_df))\n",
        "        except ValueError:\n",
        "            print('All points collected, routing ended')\n",
        "            return None, None\n",
        "\n",
        "    elif mode == 'nearest_cluster':\n",
        "        try:\n",
        "            print('Increasing number of clusters due to low order density')\n",
        "            orders_df, kmeans = run_kmeans(orders_df, vehicle_df, num_clusters=len(vehicle_df) +1 )\n",
        "        except ValueError:\n",
        "            print('All points collected, routing ended')\n",
        "            return None, None\n",
        "    else:\n",
        "        print(f\"Invalid mode '{mode}'. Please choose 'distance_threshold' or 'nearest_cluster'.\")\n",
        "        return None, None\n",
        "    return orders_df, kmeans\n",
        "\n",
        "def update_results_df(df_results,vehicle_id,collected_orders,vehicle_capacity,remaining_capacity):\n",
        "  \"\"\"This function updates the results dataframe with information about the assigned vehicle, collected orders, and remaining capacity. \"\"\"\n",
        "  new_row = {\n",
        "      'vehicle_id': vehicle_id,\n",
        "      'orders': collected_orders,\n",
        "      'vehicle_capacity': vehicle_capacity,\n",
        "      'remaining_capacity':remaining_capacity\n",
        "      }\n",
        "\n",
        "  df_results.loc[len(df_results)] = new_row\n",
        "  return df_results\n",
        "\n",
        "def calculate_total_distance(df_results, orders_df,leaving_point):\n",
        "    \"\"\" This function calculates the total distance traveled by each vehicle.\"\"\"\n",
        "    total_distances = {}\n",
        "    for idx, row in df_results.iterrows():\n",
        "        vehicle_id = row['vehicle_id']\n",
        "        orders = row['orders']\n",
        "        total_distance = 0\n",
        "\n",
        "        current_location = leaving_point  # Start from the depot\n",
        "        for order_id in orders:\n",
        "            order_location = orders_df.loc[orders_df['order_id'] == order_id, ['latitude', 'longitude']].values[0]\n",
        "            distance = haversine(current_location, order_location)\n",
        "            total_distance += distance\n",
        "            current_location = order_location\n",
        "\n",
        "        # Return to the depot\n",
        "        distance_to_depot = haversine(current_location, leaving_point)\n",
        "        total_distance += distance_to_depot\n",
        "\n",
        "        total_distances[vehicle_id] = total_distance\n",
        "\n",
        "    return total_distances\n"
      ],
      "metadata": {
        "id": "kQv0OkIC5OoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data reading 1"
      ],
      "metadata": {
        "id": "V7epsKnuj_2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# orders with 2 special care\n",
        "data_file_path = 'drive/My Drive/VRP/Orders.csv'\n",
        "\n",
        "orders_df = pd.read_csv(data_file_path)\n",
        "\n",
        "# full vehicle\n",
        "vehicle_file_path = 'drive/My Drive/VRP/vehicle_data.csv'\n",
        "\n",
        "vehicle_df = pd.read_csv(vehicle_file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZacxwzTv6boK",
        "outputId": "1aff5ff9-1cec-4791-83cc-083e66fe2996"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clustering Options"
      ],
      "metadata": {
        "id": "JbiGOsFDkJjJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mode 1 - Distance threshold"
      ],
      "metadata": {
        "id": "fCYJEO3gkO-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders_df= pd.read_csv(data_file_path)\n",
        "vehicle_df = pd.read_csv(vehicle_file_path)\n",
        "\n",
        "columns = ['vehicle_id', 'orders', 'vehicle_capacity', 'remaining_capacity']\n",
        "\n",
        "# Create an empty DataFrame\n",
        "df_results = pd.DataFrame(columns=columns)\n",
        "num_orders = len(orders_df)\n",
        "# while there is a vehicle available, do the collection\n",
        "while len(vehicle_df)>=1:\n",
        "  vehicle_id = vehicle_df.iloc[0]['vehicle_id']\n",
        "  print(f'\\n\\n collecting for vehicle {vehicle_id}\\n')\n",
        "\n",
        "\n",
        "  orders_df = combine_lat_lon(orders_df)\n",
        "\n",
        "  orders_df,kmeans = perform_clustering(orders_df, vehicle_df,\"distance_threshold\")\n",
        "\n",
        "  if kmeans == None:\n",
        "    print('all possible points are collected, routing ended')\n",
        "    break\n",
        "  leaving_point = (52.499773, -2.024925)\n",
        "\n",
        "  print_clusters(orders_df, kmeans)\n",
        "  print(\"points that need to be visited\")\n",
        "  m = plot_clusters(orders_df,leaving_point)\n",
        "  display(m)\n",
        "\n",
        "  nearest_cluster, nearest_cluster_orders = get_nearest_cluster_orders(orders_df,leaving_point)\n",
        "  vehicle_id, vehicle_capacity = assign_vehicle(nearest_cluster, vehicle_df)\n",
        "  print(f'vehicle capacity is {vehicle_capacity}')\n",
        "\n",
        "  collected_orders,remaining_capacity = collect_orders(nearest_cluster,nearest_cluster_orders,\n",
        "                                                       vehicle_capacity,orders_df,\n",
        "                                                       leaving_point,\n",
        "                                                       mode='distance_threshold',\n",
        "                                                       distance_threshold = 24)\n",
        "\n",
        "  df_results = update_results_df(df_results,vehicle_id,collected_orders,vehicle_capacity,remaining_capacity)\n",
        "\n",
        "  orders_df = remove_collected_orders(orders_df, collected_orders)\n",
        "\n",
        "  vehicle_df = remove_vehicle(vehicle_df, vehicle_id)\n",
        "\n",
        "  print(\"Collected Orders:\", collected_orders)\n",
        "  print(\"Vehicle Assigned:\", vehicle_id)\n"
      ],
      "metadata": {
        "id": "FmA0KufD7Rc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print (f\" from {num_orders} orders, {num_orders - len(orders_df)} - {100*((num_orders - len(orders_df))/num_orders)}% were collected, using all vehicles and {len(orders_df)} orders were not collected \\n\\n\")\n",
        "orders_df"
      ],
      "metadata": {
        "id": "7XRfdKgY7YpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### post processing:\n",
        "if any special care were left out, get the closest collected points from it and if it is not a special care case , keep removing from route, until the point can be collected"
      ],
      "metadata": {
        "id": "xPuY0tmVz33P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uncollected_points = orders_df.copy()\n",
        "\n",
        "uncollected_points"
      ],
      "metadata": {
        "id": "Wt8qs2Oq7eRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "special_care_uncollected = uncollected_points[uncollected_points['special_care']==1]\n",
        "\n",
        "special_care_uncollected"
      ],
      "metadata": {
        "id": "khJ7ommzkYUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orders_df= pd.read_csv(data_file_path)\n",
        "collected_points = orders_df[~orders_df.isin(uncollected_points)].dropna()"
      ],
      "metadata": {
        "id": "1lpYXQERkqpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_results_preprocessed =  df_results.copy()\n",
        "df_results_preprocessed"
      ],
      "metadata": {
        "id": "zuQ8chDckvQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_results = df_results_preprocessed.copy()\n",
        "\n",
        "if len(special_care_uncollected) >= 1:\n",
        "\n",
        "  collected_points = combine_lat_lon(collected_points)\n",
        "\n",
        "  # for all points not collected, find nearest points at collected orders\n",
        "  for idx, order in special_care_uncollected.iterrows():\n",
        "        display(special_care_uncollected)\n",
        "        # inicialize var to only collect one point\n",
        "        index_to_collect = -1\n",
        "        id_special_care_order = order['order_id']\n",
        "        order_special_weight = order['order_weight']\n",
        "        print(f'\\n \\n trying to add order {id_special_care_order} with weight {order_special_weight}')\n",
        "\n",
        "        collected_points['distance_to_leaving_point'] = collected_points['coordinates'].apply(lambda x: haversine(x, order['coordinates']))\n",
        "        collected_points = collected_points.sort_values(by='distance_to_leaving_point')\n",
        "        collected_points['order_id'] = collected_points['order_id'].astype(int)\n",
        "        print('closest orders')\n",
        "        display(collected_points)\n",
        "\n",
        "        # display(df_results)\n",
        "        for index_collected, order_collected in collected_points.iterrows():\n",
        "          if index_to_collect == -1:\n",
        "            if order_collected['special_care'] == 0:\n",
        "              index_to_collect = index_collected\n",
        "\n",
        "              order_id =  order_collected['order_id']\n",
        "              rm_order_weight = order_collected['order_weight']\n",
        "              print(f'try to remove order {order_id}')\n",
        "\n",
        "        for index, row in df_results.iterrows():\n",
        "          print( row['orders'])\n",
        "          if order_id in row['orders']:\n",
        "            print(index,row['orders'])\n",
        "            collected_by_truck = row['vehicle_id']\n",
        "            final_truck_weight =  row['remaining_capacity']\n",
        "            truck_capacity =  row['vehicle_capacity']\n",
        "            after_collecting_weight = final_truck_weight + rm_order_weight - order_special_weight\n",
        "            print(f'need to collect {order_special_weight} \\n analysing order id {order_id} with weight {rm_order_weight} \\n for truck {collected_by_truck} that previously ended up with {final_truck_weight} and can carry {truck_capacity} leaving a weight of {after_collecting_weight}')\n",
        "            print(after_collecting_weight)\n",
        "            if after_collecting_weight >= 0:\n",
        "              print(\"collecting point\")\n",
        "              print( row['orders'])\n",
        "              # Find the index of the order_id previously collected\n",
        "              index_of_previous_order = row['orders'].index(order_id)\n",
        "\n",
        "              # Replace index_of_previous_order with id_special_care_order\n",
        "              row['orders'][index_of_previous_order] = id_special_care_order\n",
        "              print( row['orders'])\n",
        "\n",
        "              df_results.loc[df_results['vehicle_id'] == collected_by_truck, 'remaining_capacity'] = after_collecting_weight\n",
        "\n",
        "\n",
        "            else:\n",
        "              print(\"can't collect point, leaving order as uncollected\")\n",
        "\n"
      ],
      "metadata": {
        "id": "yVUpDfPI7_gH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plot route"
      ],
      "metadata": {
        "id": "ihnK27Z4FBDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# new new\n",
        "orders_df= pd.read_csv(data_file_path)\n",
        "\n",
        "orders_df['order_id'] = orders_df['order_id'].astype(int)\n",
        "\n",
        "# Call the function to plot the routes\n",
        "#lot_routes_with_points(df_results, orders_df, depot_coordinates=(52.499773, -2.024925))"
      ],
      "metadata": {
        "id": "TV8WukEE8LAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orders_df= pd.read_csv(data_file_path)\n",
        "\n",
        "orders_df = combine_lat_lon(orders_df)\n",
        "\n",
        "total_distances = calculate_total_distance(df_results, orders_df,leaving_point)\n",
        "\n",
        "df_results['total_distance (mi)'] = df_results['vehicle_id'].map(total_distances)\n",
        "\n",
        "total_distance = sum(df_results['total_distance (mi)'])\n",
        "\n",
        "print(f'total distance travelled: {total_distance} miles')\n",
        "\n",
        "total_remaining_capacity = sum(df_results['remaining_capacity'])\n",
        "\n",
        "print(f'total capacity left: {total_remaining_capacity}')\n",
        "\n",
        "df_results"
      ],
      "metadata": {
        "id": "otzbpisU_cyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_results.to_csv('drive/My Drive/VRP/vehicle_allocation_distance_treshold.csv',index=False)"
      ],
      "metadata": {
        "id": "9mWZqo-OcYSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mode 2 - Only one nearest cluster"
      ],
      "metadata": {
        "id": "7gvog64Jkqme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders_df= pd.read_csv(data_file_path)\n",
        "vehicle_df = pd.read_csv(vehicle_file_path)\n",
        "\n",
        "columns = ['vehicle_id', 'orders', 'vehicle_capacity', 'remaining_capacity']\n",
        "\n",
        "# Create an empty DataFrame\n",
        "df_results = pd.DataFrame(columns=columns)\n",
        "num_orders = len(orders_df)\n",
        "# while there is a vehicle available, do the collection\n",
        "while len(vehicle_df)>=1:\n",
        "  vehicle_id = vehicle_df.iloc[0]['vehicle_id']\n",
        "  print(f'\\n\\n collecting for vehicle {vehicle_id}\\n')\n",
        "\n",
        "  orders_df = combine_lat_lon(orders_df)\n",
        "  orders_df,kmeans = perform_clustering(orders_df, vehicle_df,\"nearest_cluster\")\n",
        "\n",
        "  if kmeans == None:\n",
        "    print('all possible points are collected, routing ended')\n",
        "    break\n",
        "\n",
        "  leaving_point = (52.499773, -2.024925)\n",
        "\n",
        "  print_clusters(orders_df, kmeans)\n",
        "  print(\"points that need to be visited\")\n",
        "  m = plot_clusters(orders_df,leaving_point)\n",
        "  display(m)\n",
        "\n",
        "  nearest_cluster, nearest_cluster_orders = get_nearest_cluster_orders(orders_df,leaving_point)\n",
        "  vehicle_id, vehicle_capacity = assign_vehicle(nearest_cluster, vehicle_df)\n",
        "  print(f'vehicle capacity is {vehicle_capacity}')\n",
        "\n",
        "  collected_orders,remaining_capacity = collect_orders(nearest_cluster,nearest_cluster_orders,\n",
        "                                                       vehicle_capacity,orders_df,\n",
        "                                                       leaving_point,\n",
        "                                                       mode='nearest_cluster')\n",
        "\n",
        "  df_results = update_results_df(df_results,vehicle_id,collected_orders,vehicle_capacity,remaining_capacity)\n",
        "\n",
        "  orders_df = remove_collected_orders(orders_df, collected_orders)\n",
        "\n",
        "  vehicle_df = remove_vehicle(vehicle_df, vehicle_id)\n",
        "\n",
        "  print(\"Collected Orders:\", collected_orders)\n",
        "  print(\"Vehicle Assigned:\", vehicle_id)\n"
      ],
      "metadata": {
        "id": "CLy10yFF8uA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print (f\" from {num_orders} orders, {num_orders - len(orders_df)} - {100*((num_orders - len(orders_df))/num_orders)}% were collected, using all vehicles and {len(orders_df)} orders were not collected \\n\\n\")\n",
        "orders_df"
      ],
      "metadata": {
        "id": "QxD2A-BH83-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### post processing:\n",
        "if any special care were left out, get the closest collected points from it and if it is not a special care case , keep removing from route, until the point can be collected"
      ],
      "metadata": {
        "id": "Gi2LJDF7QW87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uncollected_points = orders_df.copy()\n",
        "\n",
        "uncollected_points"
      ],
      "metadata": {
        "id": "IAB-TIKJQW9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "special_care_uncollected = uncollected_points[uncollected_points['special_care']==1]\n",
        "\n",
        "special_care_uncollected"
      ],
      "metadata": {
        "id": "ikIGsOh0QW9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orders_df= pd.read_csv(data_file_path)\n",
        "collected_points = orders_df[~orders_df.isin(uncollected_points)].dropna()"
      ],
      "metadata": {
        "id": "W5z1_qIkQW9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_results_preprocessed =  df_results.copy()\n",
        "df_results_preprocessed"
      ],
      "metadata": {
        "id": "2xq-_uz9QW9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_results = df_results_preprocessed.copy()\n",
        "\n",
        "if len(special_care_uncollected) >= 1:\n",
        "\n",
        "  collected_points = combine_lat_lon(collected_points)\n",
        "\n",
        "  # for all points not collected, find nearest points at collected orders\n",
        "  for idx, order in special_care_uncollected.iterrows():\n",
        "        display(special_care_uncollected)\n",
        "        # inicialize var to only collect one point\n",
        "        index_to_collect = -1\n",
        "        id_special_care_order = order['order_id']\n",
        "        order_special_weight = order['order_weight']\n",
        "        print(f'\\n \\n trying to add order {id_special_care_order} with weight {order_special_weight}')\n",
        "\n",
        "        collected_points['distance_to_leaving_point'] = collected_points['coordinates'].apply(lambda x: haversine(x, order['coordinates']))\n",
        "        collected_points = collected_points.sort_values(by='distance_to_leaving_point')\n",
        "        collected_points['order_id'] = collected_points['order_id'].astype(int)\n",
        "        print('closest orders')\n",
        "        display(collected_points)\n",
        "\n",
        "        # display(df_results)\n",
        "        for index_collected, order_collected in collected_points.iterrows():\n",
        "          if index_to_collect == -1:\n",
        "            if order_collected['special_care'] == 0:\n",
        "              index_to_collect = index_collected\n",
        "\n",
        "              order_id =  order_collected['order_id']\n",
        "              rm_order_weight = order_collected['order_weight']\n",
        "              print(f'try to remove order {order_id}')\n",
        "\n",
        "        for index, row in df_results.iterrows():\n",
        "          print( row['orders'])\n",
        "          if order_id in row['orders']:\n",
        "            print(index,row['orders'])\n",
        "            collected_by_truck = row['vehicle_id']\n",
        "            final_truck_weight =  row['remaining_capacity']\n",
        "            truck_capacity =  row['vehicle_capacity']\n",
        "            after_collecting_weight = final_truck_weight + rm_order_weight - order_special_weight\n",
        "            print(f'need to collect {order_special_weight} \\n analysing order id {order_id} with weight {rm_order_weight} \\n for truck {collected_by_truck} that previously ended up with {final_truck_weight} and can carry {truck_capacity} leaving a weight of {after_collecting_weight}')\n",
        "            print(after_collecting_weight)\n",
        "            if after_collecting_weight >= 0:\n",
        "              print(\"collecting point\")\n",
        "              print( row['orders'])\n",
        "              # Find the index of the order_id previously collected\n",
        "              index_of_previous_order = row['orders'].index(order_id)\n",
        "\n",
        "              # Replace index_of_previous_order with id_special_care_order\n",
        "              row['orders'][index_of_previous_order] = id_special_care_order\n",
        "              print( row['orders'])\n",
        "\n",
        "              df_results.loc[df_results['vehicle_id'] == collected_by_truck, 'remaining_capacity'] = after_collecting_weight\n",
        "\n",
        "\n",
        "            else:\n",
        "              print(\"can't collect point, leaving order as uncollected\")\n",
        "\n"
      ],
      "metadata": {
        "id": "NIaUgI65QW9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orders_df= pd.read_csv(data_file_path)\n",
        "\n",
        "orders_df = combine_lat_lon(orders_df)\n",
        "\n",
        "total_distances = calculate_total_distance(df_results, orders_df,leaving_point)\n",
        "\n",
        "df_results['total_distance (mi)'] = df_results['vehicle_id'].map(total_distances)\n",
        "\n",
        "total_distance = sum(df_results['total_distance (mi)'])\n",
        "\n",
        "print(f'total distance travelled: {total_distance} miles')\n",
        "\n",
        "total_remaining_capacity = sum(df_results['remaining_capacity'])\n",
        "\n",
        "print(f'total capacity left: {total_remaining_capacity}')\n",
        "\n",
        "df_results"
      ],
      "metadata": {
        "id": "c5CIqlf184hC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orders_df['order_id'] = orders_df['order_id'].astype(int)\n",
        "\n",
        "# Call the function to plot the routes\n",
        "plot_routes_with_points(df_results, orders_df, depot_coordinates=(52.499773, -2.024925))\n",
        "df_results.to_csv('drive/My Drive/VRP/vehicle_allocation_nearest_cluster.csv',index=False)"
      ],
      "metadata": {
        "id": "2vQi_GyZ88P_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data reading 2"
      ],
      "metadata": {
        "id": "pQhNLlmj9DVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_file_path = 'drive/My Drive/VRP/vehicle_allocation_nearest_cluster.csv'\n",
        "\n",
        "results_df =  pd.read_csv(results_file_path)\n",
        "\n",
        "data_file_path = 'drive/My Drive/VRP/Orders.csv'\n",
        "\n",
        "orders_df = pd.read_csv(data_file_path)"
      ],
      "metadata": {
        "id": "i0zlQ-x69Ha0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "authenticate api"
      ],
      "metadata": {
        "id": "K4AAYQKFlTRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "API_key = '' #enter your google maps api key here\n"
      ],
      "metadata": {
        "id": "Y6x-lbKc9Wy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "def seconds_to_hms(seconds):\n",
        "    timestamp = datetime.datetime.utcfromtimestamp(seconds)\n",
        "    return timestamp.strftime(\"%H:%M:%S\")\n",
        "\n",
        "def get_filtered_orders_df(results_df, vehicle_id):\n",
        "    results_df_filtered = results_df[results_df['vehicle_id'] == vehicle_id]\n",
        "    print(\"points to be collected\")\n",
        "    display(results_df_filtered)\n",
        "    list_orders = ast.literal_eval(results_df_filtered['orders'].iloc[0])\n",
        "    list_orders.append('depot')\n",
        "    orders_df_filtered = orders_df.loc[orders_df['order_id'].isin(list_orders)]\n",
        "\n",
        "    # Add depot\n",
        "    new_row_data = {'latitude': 52.499773,\n",
        "                    'longitude': -2.024925,\n",
        "                    'order_id': 0,\n",
        "                    'location': 'depot',\n",
        "                    'order_weight': 0}\n",
        "    new_row = pd.DataFrame([new_row_data])\n",
        "    orders_df_filtered = pd.concat([new_row, orders_df_filtered], ignore_index=True)\n",
        "    return orders_df_filtered, list_orders,new_row,results_df_filtered\n",
        "\n",
        "def time_constraint():\n",
        "    distance_list = []\n",
        "    time_list = []\n",
        "    row_depot =  orders_df_filtered[orders_df_filtered['order_id']==0]\n",
        "    dest_depot = (row_depot['latitude'], row_depot['longitude'])\n",
        "    total_time = 0\n",
        "    total_distance = 0\n",
        "    indices_included = 0\n",
        "    # add time back to base\n",
        "    for idx,order_ in enumerate(list_orders):\n",
        "\n",
        "      sum_until_six_hours = 0\n",
        "      print(idx,order_,len(list_orders))\n",
        "\n",
        "      if idx == len(list_orders)-1:\n",
        "        # if its the last order, origin is the point of the list matching order\n",
        "        # and destination is the depot anyway\n",
        "        print(\"last order, go to depot\")\n",
        "        row_orig = orders_df_filtered[orders_df_filtered['order_id']==list_orders[idx-1]]\n",
        "        row_dest= row_depot\n",
        "      else:\n",
        "        if idx == 0:\n",
        "          # if its the first order, origin is the depot and\n",
        "          # destination is the point of the list matching order\n",
        "          print(\"first order, go from depot\")\n",
        "          row_orig = row_depot\n",
        "          row_dest= orders_df_filtered[orders_df_filtered['order_id']==list_orders[idx]]\n",
        "\n",
        "        else:\n",
        "          # if its the some order in the middle, origin is  the point of the list matching order\n",
        "          # destination is the next point of the list matching order\n",
        "          print(\"intermediate order\")\n",
        "          row_orig = orders_df_filtered[orders_df_filtered['order_id']==list_orders[idx-1]]\n",
        "          row_dest= orders_df_filtered[orders_df_filtered['order_id']==list_orders[idx]]\n",
        "\n",
        "      origin = (row_orig['latitude'], row_orig['longitude'])\n",
        "      dest = (row_dest['latitude'], row_dest['longitude'])\n",
        "      # display(row_orig)\n",
        "      # display(row_dest)\n",
        "      print('\\n\\n')\n",
        "      # if a percentege of the time is taken, calculate time to come back\n",
        "      # if after adding it reaches 90% of the hours, add it.\n",
        "      # else, keep routing\n",
        "      if total_time >= percentage_time_filling*hours:\n",
        "        print(\"calculating time to go back\")\n",
        "\n",
        "        go_back_query = gmaps.distance_matrix(origin, dest_depot, mode='driving')\n",
        "        go_back_result_distance = go_back_query[\"rows\"][0][\"elements\"][0][\"distance\"][\"value\"]\n",
        "        # distance_list.append(result_distance)\n",
        "        go_back_result_time = go_back_query[\"rows\"][0][\"elements\"][0][\"duration\"][\"value\"]\n",
        "        # time_list.append(result_time)\n",
        "        if total_time + go_back_result_time <= max_hours*60*60:\n",
        "          print(f\"{total_time} + {go_back_result_time} dont exceed {max_hours*60*60}, keeping routing\")\n",
        "          query = gmaps.distance_matrix(origin, dest, mode='driving')\n",
        "\n",
        "          result_distance = query[\"rows\"][0][\"elements\"][0][\"distance\"][\"value\"]\n",
        "          distance_list.append(result_distance)\n",
        "          result_time = query[\"rows\"][0][\"elements\"][0][\"duration\"][\"value\"]\n",
        "          # result_time = result_time/3600\n",
        "          time_list.append(result_time)\n",
        "          total_time = total_time + result_time\n",
        "          total_distance = total_distance + result_distance\n",
        "          print(f\"added {result_time} to total time and {result_distance} to total distance\")\n",
        "          indices_included = indices_included + 1\n",
        "\n",
        "        else:\n",
        "          print(f\"{total_time + go_back_result_time} exceed {max_hours*60*60}, going to depot\")\n",
        "          distance_list.append(go_back_result_distance)\n",
        "          time_list.append(go_back_result_time)\n",
        "          total_time = total_time + go_back_result_time\n",
        "          total_distance = total_distance + go_back_result_distance\n",
        "          print(f\"added {go_back_result_time} to total time and {go_back_result_distance} to total distance\")\n",
        "          print(f\"Sum until 6 hours:{total_time} seconds, {total_time/60/60} hours\")\n",
        "          print(f\"total distance: {total_distance}\")\n",
        "          print(\"Indices of items included:\", indices_included)\n",
        "          return distance_list, time_list, total_time, total_distance, indices_included\n",
        "          # break\n",
        "      else:\n",
        "        print(f\"{total_time} hours <= {percentage_time_filling*hours} hours , keeping usual routing\")\n",
        "        query = gmaps.distance_matrix(origin, dest, mode='driving')\n",
        "\n",
        "        result_distance = query[\"rows\"][0][\"elements\"][0][\"distance\"][\"value\"]\n",
        "        distance_list.append(result_distance)\n",
        "        result_time = query[\"rows\"][0][\"elements\"][0][\"duration\"][\"value\"]\n",
        "        # result_time = result_time/3600\n",
        "        time_list.append(result_time)\n",
        "        total_time = total_time + result_time\n",
        "        total_distance = total_distance + result_distance\n",
        "        print(f\"added {result_time} to total time and {result_distance} to total distance\")\n",
        "        indices_included = indices_included + 1\n",
        "\n",
        "      print(f\"Sum until 6 hours:{total_time} seconds, {total_time/60/60} hours\")\n",
        "      print(f\"total distance: {total_distance}\")\n",
        "      print(\"Indices of items included:\", indices_included)\n",
        "    return distance_list, time_list, total_time, total_distance, indices_included\n",
        "\n",
        "def google_api_distance_matrix():\n",
        "\n",
        "  #input: CSV file with id,latitude, longitude and capacities\n",
        "  # desired output: list with matrix distance for each point consumed by or tools\n",
        "  # start1 = time.time()\n",
        "  df = orders_df_filtered_time.copy()\n",
        "  df['order_weight'] = df['order_weight'].astype(int)\n",
        "  #print(df)\n",
        "  #empty list - will be used to store calculated distances\n",
        "  time_list = []\n",
        "  distance_list = []\n",
        "  origin_id_list = []\n",
        "  destination_id_list = []\n",
        "\n",
        "  for (i1, row1) in df.iterrows():\n",
        "    #print(\"origin\")\n",
        "    #print(row1['ID'])\n",
        "    LatOrigin = row1['latitude']\n",
        "    LongOrigin = row1['longitude']\n",
        "    origin = (LatOrigin, LongOrigin)\n",
        "    origin_id = row1['order_id']\n",
        "    for (i2, row2) in  df.iterrows():\n",
        "      #print(\"destination id\")\n",
        "      #print(row2['ID'])\n",
        "      LatDestination = row2['latitude']\n",
        "      LongDestination = row2['longitude']\n",
        "      destination_id = row2['order_id']\n",
        "      destination = (LatDestination, LongDestination)\n",
        "      # print(destination,destination_id)\n",
        "      try:\n",
        "          result = gmaps.distance_matrix(origin, destination, mode='driving')\n",
        "          #uncomment for cool api logs\n",
        "          #print(result)\n",
        "          result_distance = result[\"rows\"][0][\"elements\"][0][\"distance\"][\"value\"]\n",
        "          result_time = result[\"rows\"][0][\"elements\"][0][\"duration\"][\"value\"]\n",
        "          time_list.append(result_time)\n",
        "          distance_list.append(result_distance)\n",
        "          origin_id_list.append(origin_id)\n",
        "          destination_id_list.append(destination_id)\n",
        "          #print(df)\n",
        "      except Exception as e :\n",
        "        print(f'Error consulting API: {e}')\n",
        "\n",
        "  size=(len(df.latitude))\n",
        "  # Input list initialization\n",
        "  Input = distance_list\n",
        "\n",
        "  # list of length in which we have to split\n",
        "  number_points = len(df['order_id'])\n",
        "  print(\"Number of points: \",number_points)\n",
        "\n",
        "  length_to_split = number_points*[number_points]\n",
        "  #print(length_to_split)\n",
        "\n",
        "  # Using islice\n",
        "  Inputt = iter(Input)\n",
        "  distance_matrix = [list(islice(Inputt, elem))\n",
        "            for elem in length_to_split]\n",
        "  # stop1 = time.time()\n",
        "  # Printing Output\n",
        "  print(\"API list\", Input)\n",
        "  #print(\"Split length list: \", length_to_split)\n",
        "  print(\"List of Lists\", distance_matrix)\n",
        "\n",
        "  # Input list initialization\n",
        "  Input = time_list\n",
        "\n",
        "  # list of length in which we have to split\n",
        "  number_points = len(df['order_id'])\n",
        "  print(\"Number of points: \",number_points)\n",
        "\n",
        "  length_to_split = number_points*[number_points]\n",
        "  #print(length_to_split)\n",
        "\n",
        "  # Using islice\n",
        "  Inputt = iter(Input)\n",
        "  duration_matrix = [list(islice(Inputt, elem))\n",
        "            for elem in length_to_split]\n",
        "  duration_matrix\n",
        "  return distance_matrix, duration_matrix\n",
        "\n",
        "def create_data_model():\n",
        "    \"\"\"Stores the data for the problem.\"\"\"\n",
        "    data = {}\n",
        "\n",
        "    #always 1 number bigger, because it has to return to base\n",
        "    data['distance_matrix'] = distance_matrix\n",
        "\n",
        "    capacities = df['order_weight']\n",
        "    print(capacities)\n",
        "\n",
        "    data['demands'] = df['order_weight'].values.tolist()\n",
        "    print(data['demands'])\n",
        "\n",
        "    data['vehicle_capacities'] = results_df_filtered['vehicle_capacity']\n",
        "    data['num_vehicles'] = 1\n",
        "\n",
        "    data['depot'] = 0\n",
        "    print(\"Input OR-Tools: \",data,\" \",type(data))\n",
        "    return data\n",
        "\n",
        "def extract_solution(data, manager, routing, solution):\n",
        "    \"\"\"Extracts solution data.\"\"\"\n",
        "    routes_data = []\n",
        "    total_distance = 0\n",
        "    total_load = 0\n",
        "    for vehicle_id in range(data['num_vehicles']):\n",
        "        index = routing.Start(vehicle_id)\n",
        "        route_data = []\n",
        "        route_distance = 0\n",
        "        route_load = 0\n",
        "        while not routing.IsEnd(index):\n",
        "            node_index = manager.IndexToNode(index)\n",
        "            route_load += data['demands'][node_index]\n",
        "            route_data.append(node_index)\n",
        "            previous_index = index\n",
        "            index = solution.Value(routing.NextVar(index))\n",
        "            print(route_distance)\n",
        "            route_distance_add = routing.GetArcCostForVehicle(\n",
        "                previous_index, index, vehicle_id)\n",
        "            print(f'current distance: {route_distance}, adding {route_distance_add} for node {node_index}')\n",
        "            route_distance += route_distance_add\n",
        "        route_data.append(manager.IndexToNode(index))\n",
        "        route_data.append(route_load)\n",
        "        print(route_distance)\n",
        "        route_data.append(route_distance)\n",
        "        routes_data.append(route_data)\n",
        "        total_distance += route_distance\n",
        "        total_load += route_load\n",
        "    total_data = {'Route': [], 'Distance': [], 'Load': [], 'Points': []}\n",
        "    for idx, route in enumerate(routes_data):\n",
        "        total_data['Route'].append(f'Route {idx}')\n",
        "        total_data['Distance'].append(route[-1])\n",
        "        total_data['Load'].append(route[-2])\n",
        "        total_data['Points'].append(route[:-2])  # Remove load and distance\n",
        "    return pd.DataFrame(total_data)\n",
        "\n",
        "def main():\n",
        "    \"\"\"Solve the CVRP problem.\"\"\"\n",
        "    # Instantiate the data problem.\n",
        "    data = create_data_model()\n",
        "\n",
        "    # Create the routing index manager.\n",
        "    manager = pywrapcp.RoutingIndexManager(len(data['distance_matrix']),\n",
        "                                           data['num_vehicles'], data['depot'])\n",
        "\n",
        "    # Create Routing Model.\n",
        "    routing = pywrapcp.RoutingModel(manager)\n",
        "\n",
        "    # Create and register a transit callback.\n",
        "    def distance_callback(from_index, to_index):\n",
        "        \"\"\"Returns the distance between the two nodes.\"\"\"\n",
        "        # Convert from routing variable Index to distance matrix NodeIndex.\n",
        "        from_node = manager.IndexToNode(from_index)\n",
        "        to_node = manager.IndexToNode(to_index)\n",
        "        return data['distance_matrix'][from_node][to_node]\n",
        "\n",
        "    transit_callback_index = routing.RegisterTransitCallback(distance_callback)\n",
        "    # Define cost of each arc.\n",
        "    routing.SetArcCostEvaluatorOfAllVehicles(transit_callback_index)\n",
        "\n",
        "    # Add Capacity constraint.\n",
        "    def demand_callback(from_index):\n",
        "        \"\"\"Returns the demand of the node.\"\"\"\n",
        "        # Convert from routing variable Index to demands NodeIndex.\n",
        "        from_node = manager.IndexToNode(from_index)\n",
        "        return data['demands'][from_node]\n",
        "\n",
        "    demand_callback_index = routing.RegisterUnaryTransitCallback(\n",
        "        demand_callback)\n",
        "    routing.AddDimensionWithVehicleCapacity(\n",
        "        demand_callback_index,\n",
        "        0,  # null capacity slack\n",
        "        data['vehicle_capacities'],  # vehicle maximum capacities\n",
        "        True,  # start cumul to zero\n",
        "        'Capacity')\n",
        "    # Setting first solution heuristic.\n",
        "    search_parameters = pywrapcp.DefaultRoutingSearchParameters()\n",
        "    search_parameters.first_solution_strategy = (\n",
        "        routing_enums_pb2.FirstSolutionStrategy.AUTOMATIC)\n",
        "    search_parameters.local_search_metaheuristic = (\n",
        "        routing_enums_pb2.LocalSearchMetaheuristic.GUIDED_LOCAL_SEARCH)\n",
        "    search_parameters.time_limit.FromSeconds(1)\n",
        "    # Solve the problem.\n",
        "    solution = routing.SolveWithParameters(search_parameters)\n",
        "    # Print solution on console.\n",
        "    if solution:\n",
        "        solution_df = extract_solution(data, manager, routing, solution)\n",
        "        display(solution_df)\n",
        "    else:\n",
        "        print(\"no solution found\")\n",
        "    return data, manager, routing, solution_df\n",
        "\n",
        "# Function to compute total duration for a given route\n",
        "def compute_total_duration(route, duration_matrix):\n",
        "    total_duration = 0\n",
        "    for i in range(len(route) - 1):\n",
        "        from_order = route[i]\n",
        "        to_order = route[i + 1]\n",
        "        # print(from_order,to_order,duration_matrix[from_order][to_order])\n",
        "        total_duration += duration_matrix[from_order][to_order]\n",
        "        # print(total_duration)\n",
        "    return total_duration\n",
        "\n",
        "def update_results_df(results_df_filtered, list_orders_filtered, total_distance, total_time, reordered_list_orders, solution_df, total_duration):\n",
        "    \"\"\"\n",
        "    Updates the results DataFrame with clustering and ORTools results.\n",
        "    \"\"\"\n",
        "    total_distance_miles = \"{:.2f}\".format(total_distance * 0.000621371)\n",
        "    distance_ortools = \"{:.2f}\".format(solution_df['Distance'].iloc[0] * 0.000621371)\n",
        "    results_df_filtered['remaining_capacity'] = int(results_df_filtered['vehicle_capacity']) - int(solution_df['Load'])\n",
        "    results_df_filtered['orders_clustering'] = str(list_orders_filtered)\n",
        "    results_df_filtered['distance_clustering'] = f\"{total_distance_miles} mi\"\n",
        "    results_df_filtered['time_clustering'] = str(seconds_to_hms(total_time))\n",
        "    results_df_filtered['orders_ortools'] = str(reordered_list_orders)\n",
        "    results_df_filtered['distance_ortools'] = f\"{distance_ortools} mi\"\n",
        "    results_df_filtered['time_ortools'] = str (seconds_to_hms(total_duration))\n",
        "\n",
        "    try:\n",
        "        results_df_filtered.drop(columns=['orders', 'total_distance (mi)'], inplace=True)\n",
        "    except KeyError:\n",
        "        print(\"already dropped columns\")\n",
        "\n",
        "    return results_df_filtered\n",
        "\n",
        "def plot_routes_clustering(orders_df_filtered_time, list_orders_filtered):\n",
        "    \"\"\"\n",
        "    Plot routes on Google Maps based on the provided orders DataFrame and list of filtered orders.\n",
        "\n",
        "    Args:\n",
        "    - orders_df_filtered_time (pd.DataFrame): DataFrame containing order data with timestamps.\n",
        "    - list_orders_filtered (list): List of filtered order IDs.\n",
        "\n",
        "    Returns:\n",
        "    - fig (gmaps.figure): Google Maps figure with plotted routes.\n",
        "    \"\"\"\n",
        "    # Fetch all necessary data upfront\n",
        "    points_data = orders_df_filtered_time[orders_df_filtered_time['order_id'].isin(list_orders_filtered)]\n",
        "\n",
        "    # Rearrange the filtered data based on the order in list_orders_filtered\n",
        "    points_data = points_data.set_index('order_id').loc[list_orders_filtered].reset_index()\n",
        "\n",
        "    points = points_data[['latitude', 'longitude']].values.tolist()\n",
        "    # Start with the depot\n",
        "    points.insert(0, (52.49, -2.02))  # Depot coordinates\n",
        "    points_set = [tuple(point) for point in points]\n",
        "\n",
        "    # Initialize the figure\n",
        "    fig = gmaps.figure(layout={\n",
        "        'width': '1200px',\n",
        "        'height': '1200px',\n",
        "        'padding': '3px',\n",
        "        'border': '1px solid black'\n",
        "    })\n",
        "\n",
        "    cmap = plt.cm.get_cmap('Dark2', len(points_set))\n",
        "    colors = [matplotlib.colors.to_rgb(cmap(i)) for i in range(len(points_set))]\n",
        "\n",
        "    # Plot routes in order\n",
        "    for i in range(len(points) - 1):\n",
        "        start_point = points[i]\n",
        "        end_point = points[i + 1]\n",
        "        rgb_tuple = tuple(int(x * 255) for x in colors[i])\n",
        "        route = gmaps.directions_layer(start_point, end_point, travel_mode='DRIVING', show_route=True,\n",
        "                                        stroke_color=rgb_tuple, show_markers=False)\n",
        "        try:\n",
        "          fig.add_layer(route)\n",
        "        except AssertionError:\n",
        "          print(\"too many points to plot in the map, dividing it\")\n",
        "\n",
        "    # Add the last route back to the depot\n",
        "    route = gmaps.directions_layer(points[-1], points[0], travel_mode='DRIVING', show_route=True, show_markers=False)\n",
        "    try:\n",
        "      fig.add_layer(route)\n",
        "    except AssertionError:\n",
        "      print(\"too many points to plot in the map, dividing it\")\n",
        "\n",
        "    labels = [str(point) for point in list_orders_filtered]\n",
        "    if \"Depot\" not in labels:\n",
        "        labels.insert(0, \"Depot\")  # Depot coordinates\n",
        "    marker_layer = gmaps.marker_layer(\n",
        "        points_set,\n",
        "        label=labels,\n",
        "    )\n",
        "    fig.add_layer(marker_layer)\n",
        "    return fig\n",
        "\n",
        "def plot_routes_ortools(orders_df_filtered_time, reordered_list_orders):\n",
        "    \"\"\"\n",
        "    Plot routes on Google Maps based on the provided orders DataFrame and list of reordered orders.\n",
        "    Args:\n",
        "    - orders_df_filtered_time (pd.DataFrame): DataFrame containing order data with timestamps.\n",
        "    - reordered_list_orders (list): List of reordered order IDs.\n",
        "\n",
        "    Returns:\n",
        "    - fig (gmaps.figure): Google Maps figure with plotted routes.\n",
        "    \"\"\"\n",
        "    # Fetch all necessary data upfront\n",
        "    points_data = orders_df_filtered_time[orders_df_filtered_time['order_id'].isin(reordered_list_orders)]\n",
        "\n",
        "    # Rearrange the filtered data based on the order in reordered_list_orders\n",
        "    points_data = points_data.set_index('order_id').loc[reordered_list_orders].reset_index()\n",
        "\n",
        "    points = points_data[['latitude', 'longitude']].values.tolist()\n",
        "    # Start with the depot\n",
        "    points.insert(0, (52.49, -2.02))  # Depot coordinates\n",
        "    points_set = [tuple(point) for point in points]\n",
        "\n",
        "    # Initialize the figure\n",
        "    fig = gmaps.figure(layout={\n",
        "        'width': '1200px',\n",
        "        'height': '1200px',\n",
        "        'padding': '3px',\n",
        "        'border': '1px solid black'\n",
        "    })\n",
        "\n",
        "    cmap = plt.cm.get_cmap('Dark2', len(points_set))\n",
        "    colors = [matplotlib.colors.to_rgb(cmap(i)) for i in range(len(points_set))]\n",
        "\n",
        "    # Plot routes in order\n",
        "    for i in range(len(points) - 1):\n",
        "        start_point = points[i]\n",
        "        end_point = points[i + 1]\n",
        "        rgb_tuple = tuple(int(x * 255) for x in colors[i])\n",
        "        route = gmaps.directions_layer(start_point, end_point, travel_mode='DRIVING', show_route=True,\n",
        "                                        stroke_color=rgb_tuple, show_markers=False)\n",
        "        try:\n",
        "          fig.add_layer(route)\n",
        "        except AssertionError:\n",
        "          print(\"too many points to plot in the map, dividing it\")\n",
        "    # Add the last route back to the depot\n",
        "    route = gmaps.directions_layer(points[-1], points[0], travel_mode='DRIVING', show_route=True, show_markers=False)\n",
        "    try:\n",
        "      fig.add_layer(route)\n",
        "    except AssertionError:\n",
        "      print(\"too many points to plot in the map, dividing it\")\n",
        "\n",
        "    labels = [str(point) for point in reordered_list_orders]\n",
        "    if \"Depot\" not in labels:\n",
        "        labels.insert(0, \"Depot\")  # Depot coordinates\n",
        "    marker_layer = gmaps.marker_layer(\n",
        "        points_set,\n",
        "        label=labels,\n",
        "    )\n",
        "    fig.add_layer(marker_layer)\n",
        "\n",
        "    return fig"
      ],
      "metadata": {
        "id": "Yeu8KPLe9Zls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### choose vehicles ids to perform routing"
      ],
      "metadata": {
        "id": "ydHd8Y4OMX9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vehicle_ids_list = [100,101,102,103,104]"
      ],
      "metadata": {
        "id": "xwJrkD2x9gcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# select True to run just time constraint part with few requests and not full distance matrix - good for testing\n",
        "run_just_time = False\n",
        "\n",
        "# select True to plot and False to skip this part\n",
        "plot_routes = False\n",
        "# Iterate over vehicle ids\n",
        "for vehicle_id in vehicle_ids_list:\n",
        "    print(\"\\n\\n\\n\\n--------------------------------------------------------------\")\n",
        "    print(f\"Performing route comparison for vehicle {vehicle_id}\")\n",
        "    import googlemaps\n",
        "    try:\n",
        "        gmaps = googlemaps.Client(key=API_key)\n",
        "    except ValueError as e :\n",
        "        print(f'Error consulting API: {e}')\n",
        "    # Get filtered orders dataframe and list of orders\n",
        "    orders_df_filtered, list_orders,new_row,results_df_filtered = get_filtered_orders_df(results_df, vehicle_id)\n",
        "\n",
        "    print(\"Points to be collected:\")\n",
        "    #display(orders_df_filtered)\n",
        "    # display(list_orders)\n",
        "\n",
        "    # Compute route duration\n",
        "    hours = 8\n",
        "    # minimum percentage to check how long it takes to go back to depot\n",
        "    percentage_time_filling = 0.7\n",
        "    # time to stop routing 0.1 is stopping when it reaches 0.6 hour\n",
        "    max_hours = hours\n",
        "\n",
        "    distance_list, time_list, total_time, total_distance, indices_included = time_constraint()\n",
        "\n",
        "    list_orders_filtered = list_orders[:indices_included]\n",
        "    if 'depot' in list_orders_filtered:\n",
        "      list_orders_filtered.remove('depot')\n",
        "\n",
        "    print(f'\\n\\n list_orders filtered with with time constraint is{list_orders_filtered} from {list_orders}')\n",
        "\n",
        "    print(\"rebuilding dataframe of orders, now it is:\\n\")\n",
        "    orders_df_filtered_time = orders_df_filtered.loc[orders_df_filtered['order_id'].isin(list_orders_filtered)]\n",
        "    orders_df_filtered_time = pd.concat([new_row, orders_df_filtered_time], ignore_index=True)\n",
        "    #display(orders_df_filtered_time)\n",
        "\n",
        "    print(\"\\n\\n calculating distance matrix for remaining points\")\n",
        "    if run_just_time == True:\n",
        "      print(\"stopping and running just time\")\n",
        "    else:\n",
        "      distance_matrix, duration_matrix =  google_api_distance_matrix()\n",
        "\n",
        "      print(f'distance matrix: \\n {distance_matrix} \\n time matrix: \\n {duration_matrix}')\n",
        "\n",
        "      print(\"\\n\\n calculating ortools with distance matrix\")\n",
        "      Output = distance_matrix\n",
        "      num_points = len(distance_matrix)\n",
        "      print(num_points)\n",
        "\n",
        "      df =  orders_df_filtered_time.copy()\n",
        "\n",
        "      df['order_weight'] = df['order_weight'].astype(int)\n",
        "\n",
        "      data, manager, routing, solution_df = main()\n",
        "      collected_points = solution_df['Points']\n",
        "      for i in collected_points:\n",
        "        result_ortools = i\n",
        "\n",
        "      result_ortools.pop(0)\n",
        "\n",
        "      result_ortools.pop(-1)\n",
        "\n",
        "      # reordered_list_orders = [list_orders_filtered[index - 1] for index in result_ortools]\n",
        "      reordered_list_orders = [orders_df_filtered_time.iloc[idx]['order_id'] for idx in result_ortools]\n",
        "\n",
        "      reordered_list_orders_calculation = [0] + result_ortools + [0]\n",
        "      # Compute total duration for the specified route\n",
        "      total_duration = compute_total_duration(reordered_list_orders_calculation, duration_matrix)\n",
        "      print(\"Total duration for the specified route:\", total_duration)\n",
        "\n",
        "      updated_results_df = update_results_df(results_df_filtered, list_orders_filtered, total_distance, total_time, reordered_list_orders, solution_df, total_duration)\n",
        "      display(updated_results_df)\n",
        "      if plot_routes == True:\n",
        "        import gmaps\n",
        "        try:\n",
        "            gmaps.configure(api_key=API_key)\n",
        "        except ValueError as e :\n",
        "            print(f'Error consulting API: {e}')\n",
        "\n",
        "        print(\"clustering route\")\n",
        "\n",
        "        fig = plot_routes_clustering(orders_df_filtered_time, list_orders_filtered)\n",
        "        display(fig)\n",
        "\n",
        "        print(\"ortools route\")\n",
        "        fig =  plot_routes_ortools(orders_df_filtered_time, reordered_list_orders)\n",
        "        display(fig)\n",
        "      # break"
      ],
      "metadata": {
        "id": "0t8TMRJk9igx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}